{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e90289",
   "metadata": {},
   "source": [
    "# R&D engineer test\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Build a HTTP API able to receive two sound-recording ids as input, and to provide a JSON output with an automatic classification about whether the two IDs correspond to the same actual sound-recording or not. When two SRs are the same, the classifier provides the output class `\"valid\"`, otherwise it outputs `\"invalid\"`.\n",
    "\n",
    "\n",
    "\n",
    "### Machine learning approach\n",
    "\n",
    "The candidate is not expected to implement hard-crafted rules to do the classification. Instead, we provide a groundtruth file that allows to automatically train a classifier. This groundtruth provides the actual relationship between two given sound-recording ids (also called `source_id`).\n",
    "\n",
    "On the other hand, the metadata for each sound-recording id can be found in the SQLite3 database file `db.db`.\n",
    "\n",
    "We suggest to train a simple classifier using the following four features:\n",
    "* Title similarity\n",
    "* Artists similarity\n",
    "* ISRC coincidence\n",
    "* Contributors similarity\n",
    "\n",
    "Note: string similarities can be easily computed with python package `fuzzywuzzy`.\n",
    "\n",
    "### API\n",
    "\n",
    "\n",
    "## Questions to think about\n",
    "\n",
    "In the interview, maybe we would discuss about these things:\n",
    "\n",
    "* We want to run your system to deduplicate our 100M SRs catalog: do you recommend it?\n",
    "* After developing such a system how would the system evolve over time in terms of algorithm and feedback loop?\n",
    "* What other features of the model would you select to release a new version of the model? What enhancements would be part of further developments? (algorithm, data, external sources,…)\n",
    "* How would you proceed if you want to deploy this system in AWS for large-scale usage?\n",
    "* In the future we would like to use embeddings for the task of candidates retrieval and validation. Could you present an approach of how we would do so? How could this go into production?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3da7c0-ddc3-47a0-a107-a4141a2c5c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from hpsklearn import HyperoptEstimator, any_classifier\n",
    "from hyperopt import tpe\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d12654",
   "metadata": {},
   "source": [
    "## ETL - Building the dataset for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3361d80-478b-4a0a-b84f-6f576189bc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_source_id</th>\n",
       "      <th>m_source_id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify_apidsr__2NbYAPqE6FTyQte9kW4vgr</td>\n",
       "      <td>crawler_believe__26052217</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crawler_believe__34028360</td>\n",
       "      <td>crawler_believe__34168410</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crawler_fuga__7427128907609_1_6_ITZB42136782</td>\n",
       "      <td>crawler_believe__42573832</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>crawler_believe__34168476</td>\n",
       "      <td>spotify_apidsr__3kOHtCewbmdWgMVgJ8rpkC</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify_apidsr__28JA0VuEMS8i3N6fpRXr2M</td>\n",
       "      <td>spotify_apidsr__1d6j1PD3Z8NqbCgCYKDbCy</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    q_source_id  \\\n",
       "0        spotify_apidsr__2NbYAPqE6FTyQte9kW4vgr   \n",
       "1                     crawler_believe__34028360   \n",
       "2  crawler_fuga__7427128907609_1_6_ITZB42136782   \n",
       "3                     crawler_believe__34168476   \n",
       "4        spotify_apidsr__28JA0VuEMS8i3N6fpRXr2M   \n",
       "\n",
       "                              m_source_id      tag  \n",
       "0               crawler_believe__26052217  invalid  \n",
       "1               crawler_believe__34168410    valid  \n",
       "2               crawler_believe__42573832    valid  \n",
       "3  spotify_apidsr__3kOHtCewbmdWgMVgJ8rpkC  invalid  \n",
       "4  spotify_apidsr__1d6j1PD3Z8NqbCgCYKDbCy  invalid  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth = pd.read_csv('groundtruth.csv')\n",
    "groundtruth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a17867-275b-4522-8b75-1c18e02ee066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(groundtruth.q_source_id.unique()).intersection(set(groundtruth.m_source_id.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc966e61-b192-4c59-ab48-a1c73944362d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28093, 28091)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groundtruth.q_source_id.unique()), len(groundtruth.m_source_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd794c1-2a8a-46b9-a38f-03513e95fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"db.db\")    \n",
    "soundrecording = pd.read_sql_query('SELECT sr_id, title, artists, isrcs, contributors FROM soundrecording', conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df083cc-1e7a-4641-bbed-7ab5271d9344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sr_id', 'title', 'artists', 'isrcs', 'contributors'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soundrecording.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c1e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_similarity_feature(df_data, functions, fields):\n",
    "    new_features = []\n",
    "    for function in functions:\n",
    "        for field in fields:\n",
    "            assert field + '_q' in df_data.columns\n",
    "            fuzz_function = getattr(fuzz, function)\n",
    "            df_data[f'{field}_{function}'] = df_data.apply(lambda x: fuzz_function(x[f'{field}_q'], x[f'{field}_m']), axis=1)\n",
    "            new_features.append(f'{field}_{function}')\n",
    "    return df_data, new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a317299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_sr(groundtruth, soundrecording):\n",
    "    data = groundtruth.merge(soundrecording, right_on='sr_id', left_on='q_source_id', how='inner').merge(soundrecording, right_on='sr_id', left_on='m_source_id', how='inner')\n",
    "    data.columns = [c.replace('_x', '_q').replace('_y', '_m') for c in data.columns]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb6b0d4-5e96-4636-ab88-1e6cc01be094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(input_string, features, fields, conn):\n",
    "    q_sr_id, m_sr_id = [item.split('=')[1] for item in input_string.split('&')]\n",
    "    soundrecording = pd.read_sql_query(f\"SELECT * FROM soundrecording where sr_id in ('{q_sr_id}', '{m_sr_id}')\", conn)\n",
    "    groundtruth = pd.DataFrame({'q_source_id': [q_sr_id], 'm_source_id': [m_sr_id]})\n",
    "    data = join_sr(groundtruth, soundrecording)\n",
    "    new_data, new_features = add_similarity_feature(data, features, fields)\n",
    "    new_data['isrcs_coincidence'] = (new_data['isrcs_m'] == new_data['isrcs_q']).astype(int)\n",
    "    return new_data[[*new_features, *['isrcs_coincidence']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d703e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input_string(input_string):\n",
    "        return all([item in input_string for item in ['q_sr_id=', '&', 'm_sr_id=']])\n",
    "\n",
    "def get_api_response(input_string, loaded_model, features, fields, conn):\n",
    "    if not check_input_string(input_string):\n",
    "        return {\"error\": \"Incorrect request format. Please use q_sr_id= & m_sr_id=\"}\n",
    "    else:\n",
    "        X = get_features(input_string, features, fields, conn)\n",
    "        return {\"class\": \"valid\" if loaded_model.predict(X) == 1 else \"invalid\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15606037-5e52-4db8-8cfb-4b5c32c1057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'partial_ratio',\n",
    "    'partial_token_set_ratio',\n",
    "    'partial_token_sort_ratio',\n",
    "    'ratio',\n",
    "    'token_set_ratio',\n",
    "    'token_sort_ratio'\n",
    "]\n",
    "fields = ['artists', 'contributors', 'title']\n",
    "data = join_sr(groundtruth, soundrecording)\n",
    "new_data, new_features = add_similarity_feature(data, features, fields)\n",
    "new_data['isrcs_coincidence'] = (new_data['isrcs_m'] == new_data['isrcs_q']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a80efc75-5f78-4dfb-b355-408d422092bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['target'] = new_data['tag'].apply(lambda x: 1 if x == 'valid' else 0)\n",
    "num_feature_dataset = new_data[[*new_features, *['isrcs_coincidence', 'target']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7037d0-0378-498c-b21e-229f5573dde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists_partial_ratio</th>\n",
       "      <th>contributors_partial_ratio</th>\n",
       "      <th>title_partial_ratio</th>\n",
       "      <th>artists_partial_token_set_ratio</th>\n",
       "      <th>contributors_partial_token_set_ratio</th>\n",
       "      <th>title_partial_token_set_ratio</th>\n",
       "      <th>artists_partial_token_sort_ratio</th>\n",
       "      <th>contributors_partial_token_sort_ratio</th>\n",
       "      <th>title_partial_token_sort_ratio</th>\n",
       "      <th>artists_ratio</th>\n",
       "      <th>contributors_ratio</th>\n",
       "      <th>title_ratio</th>\n",
       "      <th>artists_token_set_ratio</th>\n",
       "      <th>contributors_token_set_ratio</th>\n",
       "      <th>title_token_set_ratio</th>\n",
       "      <th>artists_token_sort_ratio</th>\n",
       "      <th>contributors_token_sort_ratio</th>\n",
       "      <th>title_token_sort_ratio</th>\n",
       "      <th>isrcs_coincidence</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>33</td>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>100</td>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>75</td>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "      <td>14</td>\n",
       "      <td>46</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artists_partial_ratio  contributors_partial_ratio  title_partial_ratio  \\\n",
       "0                     38                           0                   61   \n",
       "1                    100                         100                   84   \n",
       "2                     25                          35                   62   \n",
       "3                    100                          38                   57   \n",
       "4                     17                          40                   70   \n",
       "\n",
       "   artists_partial_token_set_ratio  contributors_partial_token_set_ratio  \\\n",
       "0                               25                                     0   \n",
       "1                              100                                   100   \n",
       "2                               25                                    35   \n",
       "3                              100                                   100   \n",
       "4                               17                                   100   \n",
       "\n",
       "   title_partial_token_set_ratio  artists_partial_token_sort_ratio  \\\n",
       "0                            100                                25   \n",
       "1                            100                               100   \n",
       "2                            100                                25   \n",
       "3                            100                               100   \n",
       "4                            100                                17   \n",
       "\n",
       "   contributors_partial_token_sort_ratio  title_partial_token_sort_ratio  \\\n",
       "0                                      0                              75   \n",
       "1                                    100                              82   \n",
       "2                                     35                              62   \n",
       "3                                     63                              62   \n",
       "4                                     53                              67   \n",
       "\n",
       "   artists_ratio  contributors_ratio  title_ratio  artists_token_set_ratio  \\\n",
       "0             13                   0           62                       15   \n",
       "1            100                 100           87                      100   \n",
       "2             25                  24           50                       25   \n",
       "3            100                  33           49                      100   \n",
       "4             14                  28           75                       14   \n",
       "\n",
       "   contributors_token_set_ratio  title_token_set_ratio  \\\n",
       "0                             0                     74   \n",
       "1                           100                    100   \n",
       "2                            26                     62   \n",
       "3                            79                     65   \n",
       "4                            79                    100   \n",
       "\n",
       "   artists_token_sort_ratio  contributors_token_sort_ratio  \\\n",
       "0                        13                              0   \n",
       "1                       100                            100   \n",
       "2                        25                             26   \n",
       "3                       100                             57   \n",
       "4                        14                             46   \n",
       "\n",
       "   title_token_sort_ratio  isrcs_coincidence  target  \n",
       "0                      74                  0       0  \n",
       "1                      80                  0       1  \n",
       "2                      62                  0       0  \n",
       "3                      51                  0       1  \n",
       "4                      79                  0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feature_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107ffa3",
   "metadata": {},
   "source": [
    "## Training the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba5d248-da68-45a4-a3bf-e05f0eb29a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = num_feature_dataset.drop('target', axis=1)\n",
    "y = num_feature_dataset['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "796fba00-391b-475c-94e6-bf05608dba52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9679589875040051"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.4, max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d58f9aa2-604a-4991-b7f1-e65a6fbeb307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/trial, best loss: 0.05207785376117835]\n",
      "100%|██████████| 2/2 [00:03<00:00,  3.67s/trial, best loss: 0.0352446081009995]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.36s/trial, best loss: 0.0352446081009995]\n",
      "100%|██████████| 4/4 [00:04<00:00,  4.66s/trial, best loss: 0.0352446081009995]\n",
      "100%|██████████| 5/5 [00:01<00:00,  1.96s/trial, best loss: 0.0352446081009995]\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.29s/trial, best loss: 0.0352446081009995]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.19s/trial, best loss: 0.0352446081009995]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.27s/trial, best loss: 0.032877432930036865]\n",
      "100%|██████████| 9/9 [00:05<00:00,  5.25s/trial, best loss: 0.032877432930036865]\n",
      "100%|██████████| 10/10 [00:01<00:00,  1.28s/trial, best loss: 0.032877432930036865]\n",
      "0.962512015379686\n",
      "{'learner': GradientBoostingClassifier(learning_rate=0.020906439945477112,\n",
      "                           loss='exponential', max_features='log2',\n",
      "                           max_leaf_nodes=15, min_samples_leaf=4,\n",
      "                           n_estimators=53, random_state=2, verbose=False), 'preprocs': (StandardScaler(),), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javi/anaconda3/envs/dole/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "estim = HyperoptEstimator(classifier=any_classifier('clf'), algo=tpe.suggest, trial_timeout=300)\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "print(estim.score(X_test, y_test))\n",
    "print(estim.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1168570b-c5ff-4e23-b0ff-539cf6625e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = estim.best_model()['learner']\n",
    "# best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5b62f98-6561-45de-a0c0-2f714aace9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'best_model.sav'\n",
    "# pickle.dump(best_model, open(filename, 'wb'))\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73bbf0b0-8910-4659-b483-286fc5a77f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9679589875040051\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6a453",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51ac3dc5-4259-44b1-9184-c922fcc9e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = 'q_sr_id=spotify_apidsr__2NbYAPqE6FTyQte9kW4vgr&m_sr_id=crawler_fuga__7427128907609_1_6_ITZB42136782'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21986251-32db-42d3-86bd-542fef30b26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'invalid'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"db.db\")\n",
    "get_api_response(input_string, loaded_model, features, fields, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63d33167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'Incorrect request format. Please use q_sr_id= & m_sr_id='}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the &\n",
    "input_string = 'q_sr_id=spotify_apidsr__2NbYAPqE6FTyQte9kW4vgrm_sr_id=crawler_fuga__7427128907609_1_6_ITZB42136782'\n",
    "get_api_response(input_string, loaded_model, features, fields, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e6bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class\":\"valid\"}"
     ]
    }
   ],
   "source": [
    "!curl -X GET -d '\"q_sr_id=crawler_believe__34028360&m_sr_id=crawler_believe__34168410\"' http://localhost:8002/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46851ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
